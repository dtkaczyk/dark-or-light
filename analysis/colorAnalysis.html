<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Color Luminance Analysis</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>Color Luminance Analysis</h1>

<p>Dominika Tkaczyk
October 24, 2016</p>

<h1>Introduction</h1>

<p>In this document we analyze colors with respect to whether they are dark or light. From now on, we will call this feature luminance (<a href="https://en.wikipedia.org/wiki/Luma_%28video%29">https://en.wikipedia.org/wiki/Luma_%28video%29</a>). The analysis deals with the following main problem: how can we automatically determine whether the color is dark or light?</p>

<p>The issue is not trivial for a couple of reasons:</p>

<ul>
<li>  a color is not a single number, for which we could use a single threshold, but rather a combination of a few components (for example red, green and blue light in case of RGB model), each of which may affect the luminance differently,</li>
<li>  color&#39;s luminance is subjective and may differ depending on who is judging it,</li>
<li>  even though there are colors for which the correct answer is obvious (eg. white or black), there are also a lot of colors in case of which the answer might be ambiguous (eg. pure green).</li>
</ul>

<h2>Problem Statement</h2>

<p>We will represent colors using RGB model. In this model a color <em>c</em> is represented by a vector of three numbers <em>c* = [*c</em><sub><em>R</em></sub>, <em>c</em><sub><em>G</em></sub>, <em>c</em><sub><em>B</em></sub>], where the red, green and blue intensities are normalized, that is 0 ≤ <em>c</em><sub><em>R</em></sub>, <em>c</em><sub><em>G</em></sub>, <em>c</em><sub><em>B</em></sub> ≤ 1. In this model, white is represented by a vector <em>w</em><em>h</em><em>i</em><em>t</em><em>e* = \[1, 1, 1\], black by *b</em><em>l</em><em>a</em><em>c</em><em>k* = \[0, 0, 0\], blue will be *b</em><em>l</em><em>u</em>*e* = \[0, 0, 1\], and so on.</p>

<p>Color&#39;s luminance will be represented by a single categorical variable with two levels: <em>dark</em> and <em>light</em>.</p>

<p>The problem analyzed in this document is the following: find a function <em>L* : \[0, 1\]<sup>3</sup> → {*d</em>, <em>l</em>}, which for a given color determines its luminance.</p>

<h1>Data</h1>

<p>A dedicated dataset was prepared manualy for the purpose of this analysis. First, 300 colors were generated by randomly sampling from uniform distribution for each RGB components separately. Then the colors were labelled manually as <em>dark</em> or <em>light</em>. For manual labelling we used scatter plots of green intensity against red intensity with points coloured by the &quot;real&quot; color of the data point and labelled with its number from the data set:</p>

<p><img src="colorAnalysis_files/figure-markdown_github/buildingTestset-1.png" alt=""></p>

<h1>Exploratory Analysis</h1>

<p>Before exploring our dataset, let&#39;s first divide it into train and test sets. All the analyses, plotting and exploring will be done using only train part. In the end, the test set will be used to give a fair, reliable estimate of the prediction&#39;s error.</p>

<pre><code class="r">data &lt;- read.csv(&quot;data.csv&quot;)
set.seed(2690)
split &lt;- 0.67
trainIndex &lt;- createDataPartition(data$Lum, p = split, list = FALSE)
train &lt;- data[trainIndex,]
row.names(train) &lt;- NULL
test &lt;- data[-trainIndex,]
row.names(test) &lt;- NULL
</code></pre>

<p>Our train set contains 202 observation with 4 attributes describing each of them. Let&#39;s first see how the first few observation look like:</p>

<pre><code class="r">head(train, n = 10)
</code></pre>

<pre><code>##          Red     Green       Blue Lum
## 1  0.1908772 0.2643566 0.77019594   D
## 2  0.3598500 0.9953525 0.47292464   L
## 3  0.4264704 0.1829865 0.99107870   L
## 4  0.4966223 0.5939583 0.65299197   L
## 5  0.5033762 0.4312600 0.02559950   L
## 6  0.5233165 0.2118095 0.33238907   D
## 7  0.2373066 0.7829079 0.56263702   L
## 8  0.7839110 0.8241925 0.06574628   L
## 9  0.1950080 0.9158516 0.69571098   L
## 10 0.8520693 0.7607886 0.40480641   L
</code></pre>

<p><strong>Red</strong>, <strong>Green</strong> and <strong>Blue</strong> attributes are numeric, while <strong>Lum</strong> is a categorical variable with two levels: <em>L</em> and <em>D</em>:</p>

<pre><code class="r">str(train)
</code></pre>

<pre><code>## &#39;data.frame&#39;:    202 obs. of  4 variables:
##  $ Red  : num  0.191 0.36 0.426 0.497 0.503 ...
##  $ Green: num  0.264 0.995 0.183 0.594 0.431 ...
##  $ Blue : num  0.7702 0.4729 0.9911 0.653 0.0256 ...
##  $ Lum  : Factor w/ 2 levels &quot;D&quot;,&quot;L&quot;: 1 2 2 2 2 1 2 2 2 2 ...
</code></pre>

<p>Let&#39;s now plot the histograms of all the variables:</p>

<p><img src="colorAnalysis_files/figure-markdown_github/histograms-1.png" alt=""></p>

<p>The distributions of red, green and blue components seem fairly uniform (this is to be expected, based on how the data set was generated). The dark and light classes are also well balanced, we have similar number of observations in each class.</p>

<p>Let&#39;s also examine the boxplots of each variable divided by the luminance:</p>

<p><img src="colorAnalysis_files/figure-markdown_github/boxplots-1.png" alt=""></p>

<p>It can be clearly seen that color components affect the luminance differently:</p>

<ul>
<li>  green seems to keep the most information about the luminance; the means of green components for dark and light colors differ greatly, and the IQRs of the distributions do not overlap,</li>
<li>  red seem to be less correlated with luminance; the means are still far apart, but the IQRs are closer to each other,</li>
<li>  blue separated the dark and light colors the worst, the two distributions are pretty similar.</li>
</ul>

<p>We can also perform statistical tests to confirm these observations more formally. We will use non-parametric Kolmogorov–Smirnov test to compare two samples: red/green/blue values for dark and light colors. The p-value will indicate how probable it is that the samples come from the same distibution.</p>

<pre><code class="r">ks.test(train[train$Lum==&#39;D&#39;,]$Red, train[train$Lum==&#39;L&#39;,]$Red)
</code></pre>

<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  train[train$Lum == &quot;D&quot;, ]$Red and train[train$Lum == &quot;L&quot;, ]$Red
## D = 0.25904, p-value = 0.002317
## alternative hypothesis: two-sided
</code></pre>

<pre><code class="r">ks.test(train[train$Lum==&#39;D&#39;,]$Green, train[train$Lum==&#39;L&#39;,]$Green)
</code></pre>

<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  train[train$Lum == &quot;D&quot;, ]$Green and train[train$Lum == &quot;L&quot;, ]$Green
## D = 0.67649, p-value &lt; 2.2e-16
## alternative hypothesis: two-sided
</code></pre>

<pre><code class="r">ks.test(train[train$Lum==&#39;D&#39;,]$Blue, train[train$Lum==&#39;L&#39;,]$Blue)
</code></pre>

<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  train[train$Lum == &quot;D&quot;, ]$Blue and train[train$Lum == &quot;L&quot;, ]$Blue
## D = 0.13227, p-value = 0.3414
## alternative hypothesis: two-sided
</code></pre>

<p>As observed before, in the case of <em>Blue</em> we obtained a large p-value, suggesting that the samples are not that different. <em>Red</em> and <em>Green</em>, however, resulted in a very small p-values, so in these cases the distributions indeed vary a lot.</p>

<p>Let&#39;s also examine the correlations between the variables:</p>

<pre><code class="r">cor(train[,1:3])
</code></pre>

<pre><code>##               Red       Green        Blue
## Red    1.00000000 -0.02225762 -0.07202994
## Green -0.02225762  1.00000000 -0.05397041
## Blue  -0.07202994 -0.05397041  1.00000000
</code></pre>

<p>There seem to be no correlations between <em>Red</em>, <em>Green</em> and <em>Blue</em> componenets in our data set. Again, this is to be expected considering how the data set was built.</p>

<p>Let&#39;s also plot variables against each other and color the points with luminance:</p>

<pre><code class="r">pairs(train, col=train$Lum)
</code></pre>

<p><img src="colorAnalysis_files/figure-markdown_github/pairs-1.png" alt=""></p>

<p>The plot of <em>Red</em> vs. <em>Green</em> shows a fairly clear linear separation between the luminance classes. Similar trend can be observed in the <em>Green</em> vs. <em>Blue</em> plot, but somewhat weaker: more points of different classes lie close together in the middle area. The plot <em>Red</em> vs. <em>Blue</em> shows no pattern.</p>

<p>The initial analysis results in the following conclusions:</p>

<ul>
<li>  green components seem to be the most informative of the luminance, and blue - the least,</li>
<li>  linear methods might be a good approach to the prediction problem, as the plots show the possibility of a linear separation between dark and light classes.</li>
</ul>

<h1>Evaluation</h1>

<p>We will use the train portion of the dataset to evaluate and compare various models. Since luminance classes are balanced, we will use accuracy as the main evaluation metric. A result for a single model is an array of 10 accuracy values obtained by a 10-fold cross validation on the train set. In the first version we will compare the models using a mean of those values.</p>

<p>Function <em>evaluate</em> takes a model function and returns a vector of 10 accuracies obtained during a 10-fold cross validation. A <em>model function</em> should take two parameters: a training and a testing set, and after learning the model using the training set it should output the predicted values for the testing set. In this setting, it will be executed 10 times by the <em>evaluate</em> function with the arguments equal to 9/10 and the remaining 1/10 of the train set, respectively.</p>

<p>Example execution (this random model function ignores the training set):</p>

<pre><code class="r">modelRandom &lt;- function(training, testing) {
    set.seed(2690)
    sample(c(&quot;D&quot;, &quot;L&quot;), nrow(testing), replace = TRUE)
}
cvSummary(evaluate(train, modelRandom))
</code></pre>

<pre><code>## $mean
## [1] 0.5042857
## 
## $sd
## [1] 0.06511613
</code></pre>

<h1>Prediction Models</h1>

<h2>Baseline Models</h2>

<p>Let&#39;s start with a few simple baseline models, which do not require any training at all. We will use the following models:</p>

<ul>
<li>  <strong>modelAlwaysLight</strong> predicts <em>light</em> for all data points,</li>
<li>  <strong>modelHalfSum</strong> predicts <em>light</em> when average color components intensity is greater than or equal 0.5, that is when <em>c</em><sub><em>R</em></sub> + <em>c</em><sub><em>G</em></sub> + <em>c</em><sub><em>B</em></sub> ≥ 1.5</li>
<li>  <strong>modelStandardLuma</strong> uses the standard luma definition for digital formats (see <a href="https://en.wikipedia.org/wiki/Luma_%28video%29">https://en.wikipedia.org/wiki/Luma_%28video%29</a>)</li>
</ul>

<pre><code class="r">modelAlwaysLightResult &lt;- evaluate(train, modelAlwaysLight)
modelHalfSumResult &lt;- evaluate(train, modelHalfSum)
modelStandardLumaResult &lt;- evaluate(train, modelStandardLuma)
</code></pre>

<p>Let&#39;s also compare out baseline models visually by plotting box plots of the distributions of the accuracies obtained by each model during cross validation:</p>

<pre><code class="r">results &lt;- list(
    &quot;Always light&quot;  = modelAlwaysLightResult,
    &quot;Half sum&quot;      = modelHalfSumResult,
    &quot;Standard luma&quot; = modelStandardLumaResult
)
visualizeResults(results)
</code></pre>

<p><img src="colorAnalysis_files/figure-markdown_github/baselineVis-1.png" alt=""></p>

<p>The following table summarizes baseline models&#39; results. To compare the models more formally, we use statistical tests to find out whether the differences between the results obtained in the cross validation are statistically significant. Wilcoxon signed-rank test is used to compare the results and the models are ordered by the number of statistical wins:</p>

<pre><code>##          Method      Mean         SD       Min  Max StatWins
## 1 Standard luma 0.9052381 0.07262490 0.7500000 1.00        2
## 2      Half sum 0.7978571 0.08278695 0.6666667 0.90        1
## 3  Always light 0.5247619 0.08133430 0.4000000 0.65        0
</code></pre>

<p>We can clearly see that standard luma equation gives very good results and outperforms other baseline methods.</p>

<h2>Learning Models</h2>

<p>Now let&#39;s fit a few models to the dataset and see how they perform. We are using <em>caret</em> package which by default performs a grid search in order to find the best parameters for a model. We will try the following learning methods:</p>

<ul>
<li>  Logistic Regression</li>
<li>  Linear Discriminant Analysis and Quadratic Discriminant Analysis</li>
<li>  Naive Bayes</li>
<li>  Decision Tees and Random Forest</li>
<li>  Support Vector Machines with linear, polynomial and radial kernel</li>
<li>  K-Nearest Neighbors</li>
</ul>

<p>We will also enhance our dataset with new features:</p>

<ul>
<li>  the squares of all RGB components: <em>SqRed</em>, <em>SqGreen</em>, <em>SqBlue</em></li>
<li>  the square roots of all RGB components: <em>SqRootRed</em>, <em>SqRootGreen</em>, <em>SqRootBlue</em></li>
<li>  multiplications of the components: <em>MultRedGreen</em>, <em>MultGreenBlue</em>, <em>MultRedBlue</em>, <em>MultRedGreenBlue</em></li>
<li>  ratios of the components: <em>RatioRedGreen</em>, <em>RatioGreenRed</em>, <em>RatioedBlue</em>, <em>RatioBlueRed</em>, <em>RatioBlueGreen</em>, <em>RatioGreenBlue</em>, <em>RatioRedGreenBlue</em></li>
</ul>

<p>Each model starts with a different base sets of the features and performs feature selection within each fold (Recursive Feature Elimination using caret-provided feature importance scores).</p>

<h3>Basic Features</h3>

<p>These models use only the three basic features:</p>

<p><img src="colorAnalysis_files/figure-markdown_github/modelsBasic-1.png" alt=""></p>

<pre><code>##                 Method      Mean         SD  Min      Max StatWins
## 1             SVM poly 0.9402381 0.06151126 0.80 1.000000        3
## 2        Random forest 0.9302381 0.05385200 0.85 1.000000        3
## 3           SVM radial 0.9252381 0.07178219 0.80 1.000000        2
## 4           SVM linear 0.9152381 0.06273557 0.85 1.000000        2
## 5                  QDA 0.9154762 0.07117459 0.75 1.000000        1
## 6                  LDA 0.9002381 0.07834624 0.75 1.000000        0
## 7  Logistic regression 0.8954762 0.06035348 0.80 0.952381        0
## 8                  KNN 0.8802381 0.07175455 0.80 1.000000        0
## 9        Decision tree 0.8654762 0.07498425 0.75 1.000000        0
## 10         Naive Bayes 0.8609524 0.05754050 0.80 0.950000        0
</code></pre>

<h3>Basic Features + Multiplication Features</h3>

<p>These models use three basic features and features based on multiplication:</p>

<p><img src="colorAnalysis_files/figure-markdown_github/modelsMult-1.png" alt=""></p>

<pre><code>##                 Method      Mean         SD  Min      Max StatWins
## 1           SVM radial 0.9500000 0.05270463 0.85 1.000000        4
## 2             SVM poly 0.9354762 0.06230487 0.80 1.000000        0
## 3                  QDA 0.9352381 0.05804838 0.80 1.000000        0
## 4  Logistic regression 0.9252381 0.06357336 0.80 1.000000        0
## 5        Random forest 0.9252381 0.06780212 0.80 1.000000        0
## 6        Decision tree 0.9154762 0.04162318 0.85 0.952381        0
## 7                  LDA 0.9152381 0.07484931 0.80 1.000000        0
## 8          Naive Bayes 0.9104762 0.06181516 0.80 1.000000        0
## 9                  KNN 0.9052381 0.06869367 0.80 1.000000        0
## 10          SVM linear 0.9002381 0.08181497 0.75 1.000000        0
</code></pre>

<h3>Basic Features + Multiplication Features + Ratio Features</h3>

<p>These models use three basic features, features based on multiplication and ratio-based features:</p>

<p><img src="colorAnalysis_files/figure-markdown_github/modelsRatio-1.png" alt=""></p>

<pre><code>##                 Method      Mean         SD  Min      Max StatWins
## 1           SVM linear 0.9402381 0.05169647 0.85 1.000000        0
## 2             SVM poly 0.9402381 0.06587254 0.80 1.000000        0
## 3                  QDA 0.9352381 0.05804838 0.80 1.000000        0
## 4           SVM radial 0.9254762 0.05915814 0.80 1.000000        0
## 5  Logistic regression 0.9204762 0.04864244 0.85 0.952381        0
## 6        Random forest 0.9202381 0.07160692 0.80 1.000000        0
## 7                  KNN 0.9157143 0.04748924 0.85 1.000000        0
## 8          Naive Bayes 0.9154762 0.06288650 0.80 1.000000        0
## 9        Decision tree 0.9154762 0.04162318 0.85 0.952381        0
## 10                 LDA 0.9102381 0.08768351 0.80 1.000000        0
</code></pre>

<h3>Basic Features + Multiplication Features + Ratio Features + Square Features</h3>

<p>These models use three basic features and all additional features:</p>

<p><img src="colorAnalysis_files/figure-markdown_github/modelsSq-1.png" alt=""></p>

<pre><code>##                 Method      Mean         SD  Min      Max StatWins
## 1           SVM linear 0.9452381 0.03693675 0.90 1.000000        0
## 2             SVM poly 0.9402381 0.04601053 0.85 1.000000        0
## 3           SVM radial 0.9304762 0.04853355 0.85 1.000000        0
## 4                  KNN 0.9257143 0.04236638 0.85 1.000000        0
## 5                  QDA 0.9207143 0.05866631 0.80 1.000000        0
## 6        Decision tree 0.9154762 0.04162318 0.85 0.952381        0
## 7        Random forest 0.9154762 0.05332542 0.85 1.000000        0
## 8                  LDA 0.9007143 0.08182728 0.75 1.000000        0
## 9  Logistic regression 0.9004762 0.06668367 0.80 1.000000        0
## 10         Naive Bayes 0.9004762 0.08530029 0.70 0.952381        0
</code></pre>

<h3>Model Comparison</h3>

<p>Now we will compare all the models built so far, including the baseline models:</p>

<pre><code>##                         Method    Mean      SD     Min     Max StatWins
## 1            SVM radial (mult) 0.95000 0.05270 0.85000 1.00000       17
## 2           SVM linear (ratio) 0.94024 0.05170 0.85000 1.00000       11
## 3             SVM poly (ratio) 0.94024 0.06587 0.80000 1.00000       10
## 4              SVM linear (sq) 0.94524 0.03694 0.90000 1.00000        8
## 5             SVM poly (basic) 0.94024 0.06151 0.80000 1.00000        8
## 6              SVM poly (mult) 0.93548 0.06230 0.80000 1.00000        7
## 7                SVM poly (sq) 0.94024 0.04601 0.85000 1.00000        6
## 8              SVM radial (sq) 0.93048 0.04853 0.85000 1.00000        5
## 9        Random forest (basic) 0.93024 0.05385 0.85000 1.00000        5
## 10        Random forest (mult) 0.92524 0.06780 0.80000 1.00000        5
## 11                  QDA (mult) 0.93524 0.05805 0.80000 1.00000        4
## 12                 QDA (ratio) 0.93524 0.05805 0.80000 1.00000        4
## 13                    KNN (sq) 0.92571 0.04237 0.85000 1.00000        4
## 14          SVM radial (ratio) 0.92548 0.05916 0.80000 1.00000        4
## 15          SVM radial (basic) 0.92524 0.07178 0.80000 1.00000        4
## 16  Logistic regression (mult) 0.92524 0.06357 0.80000 1.00000        4
## 17 Logistic regression (ratio) 0.92048 0.04864 0.85000 0.95238        4
## 18       Random forest (ratio) 0.92024 0.07161 0.80000 1.00000        4
## 19                 KNN (ratio) 0.91571 0.04749 0.85000 1.00000        4
## 20        Decision tree (mult) 0.91548 0.04162 0.85000 0.95238        4
## 21         Naive Bayes (ratio) 0.91548 0.06289 0.80000 1.00000        4
## 22       Decision tree (ratio) 0.91548 0.04162 0.85000 0.95238        4
## 23          Decision tree (sq) 0.91548 0.04162 0.85000 0.95238        4
## 24          SVM linear (basic) 0.91524 0.06274 0.85000 1.00000        4
## 25                  LDA (mult) 0.91524 0.07485 0.80000 1.00000        4
## 26                    QDA (sq) 0.92071 0.05867 0.80000 1.00000        3
## 27                 QDA (basic) 0.91548 0.07117 0.75000 1.00000        3
## 28          Random forest (sq) 0.91548 0.05333 0.85000 1.00000        3
## 29          Naive Bayes (mult) 0.91048 0.06182 0.80000 1.00000        3
## 30                 LDA (ratio) 0.91024 0.08768 0.80000 1.00000        3
## 31               Standard luma 0.90524 0.07262 0.75000 1.00000        3
## 32                  KNN (mult) 0.90524 0.06869 0.80000 1.00000        3
## 33                    LDA (sq) 0.90071 0.08183 0.75000 1.00000        2
## 34    Logistic regression (sq) 0.90048 0.06668 0.80000 1.00000        2
## 35            Naive Bayes (sq) 0.90048 0.08530 0.70000 0.95238        2
## 36                 LDA (basic) 0.90024 0.07835 0.75000 1.00000        2
## 37           SVM linear (mult) 0.90024 0.08181 0.75000 1.00000        2
## 38 Logistic regression (basic) 0.89548 0.06035 0.80000 0.95238        2
## 39                 KNN (basic) 0.88024 0.07175 0.80000 1.00000        1
## 40       Decision tree (basic) 0.86548 0.07498 0.75000 1.00000        1
## 41         Naive Bayes (basic) 0.86095 0.05754 0.80000 0.95000        1
## 42                    Half sum 0.79786 0.08279 0.66667 0.90000        1
## 43                Always light 0.52476 0.08133 0.40000 0.65000        0
</code></pre>

<p>This is a visualizaton of 10 best models:</p>

<p><img src="colorAnalysis_files/figure-markdown_github/visAll-1.png" alt=""></p>

<p>It seems that SVM model with radial kernel and basic combined with multiplication-based features achieves the best results, at the same time beating the most other models in statistical tests. Let&#39;s make one final evaluation of the winning model using the held-out dataset:</p>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  D  L
##          D 43  3
##          L  2 50
##                                           
##                Accuracy : 0.949           
##                  95% CI : (0.8849, 0.9832)
##     No Information Rate : 0.5408          
##     P-Value [Acc &gt; NIR] : &lt;2e-16          
##                                           
##                   Kappa : 0.8974          
##  Mcnemar&#39;s Test P-Value : 1               
##                                           
##             Sensitivity : 0.9556          
##             Specificity : 0.9434          
##          Pos Pred Value : 0.9348          
##          Neg Pred Value : 0.9615          
##              Prevalence : 0.4592          
##          Detection Rate : 0.4388          
##    Detection Prevalence : 0.4694          
##       Balanced Accuracy : 0.9495          
##                                           
##        &#39;Positive&#39; Class : D               
## 
</code></pre>

<h1>Conclusions</h1>

<p>In this document we examined the possibility of automated classifying a given color as <em>light</em> or <em>dark</em> based on their RGB components. The most important findings of the analysis include:</p>

<ul>
<li>  the problem is not trivial, but fairly easy to solve with standard machine learning approach</li>
<li>  green component is the most correlated with the target luminance, and blue component - the least</li>
<li>  a simple linear model based on the standard luma definition for digital formats performs well, acheiving the mean accuracy of 0.9052381 on our training set</li>
<li>  the best model found is SVM model with radial kernel and basic combined with multiplication-based features, achieving the mean accuracy of 0.95 on our training set</li>
<li>  the accuracy of the best model on our held-out set (and thus our best estimate for the accuracy of the chosen solution is 0.9489796</li>
</ul>

<p>Limitations:</p>

<ul>
<li>  Current document lacks error analysis. Maybe examining the most typical errors could result in futher improvement?</li>
<li>  For time performance purposes, we used the default model parameter choosing functionality provided by caret, which is limited to checking a few values only. Perhaps fine-tuning the chosen model would increase the overall acuracy as well?</li>
</ul>

</body>

</html>
